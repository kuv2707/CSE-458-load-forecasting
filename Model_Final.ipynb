{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c94978cc-88b9-425b-b519-328e73bed807",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-15 16:45:01.370962: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-15 16:45:01.465457: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-15 16:45:01.465993: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-15 16:45:01.579697: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-15 16:45:02.934527: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import skfuzzy as fuzz\n",
    "from skfuzzy import control as ctrl\n",
    "import warnings\n",
    "import datetime\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73db44c1-d1b8-47c5-8519-834dc0bfa94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Data Loading and Preprocessing\n",
    "def load_data(file_path):\n",
    "    \"\"\"\n",
    "    Load and preprocess the electrical load data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the data\n",
    "        data = pd.read_csv(file_path)\n",
    "        \n",
    "        print(f\"Data loaded successfully with {data.shape[0]} rows and {data.shape[1]} columns.\")\n",
    "        \n",
    "        # Extract hour from datetime\n",
    "        if 'Datetime' in data.columns:\n",
    "            data['Datetime'] = pd.to_datetime(data['Datetime'])\n",
    "            data['Hour'] = data['Datetime'].dt.hour\n",
    "            data['Date'] = data['Datetime'].dt.date\n",
    "        \n",
    "        # Print some basic statistics\n",
    "        print(\"\\nData summary:\")\n",
    "        print(f\"Time period: {data['Datetime'].min()} to {data['Datetime'].max()}\")\n",
    "        print(f\"States in the dataset: {data['State'].unique()}\")\n",
    "        print(f\"Load value range: {data['Value'].min()} to {data['Value'].max()}\")\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02ad5b90-4a38-4fa2-abba-bb712a324f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. LSTM Model for Load Prediction\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    \"\"\"\n",
    "    Create time series dataset for LSTM.\n",
    "    \"\"\"\n",
    "    X, Y = [], []\n",
    "    for i in range(len(dataset) - time_step - 1):\n",
    "        a = dataset[i:(i + time_step), 0]\n",
    "        X.append(a)\n",
    "        Y.append(dataset[i + time_step, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "def build_lstm_model(data, state_name, time_step=24):\n",
    "    \"\"\"\n",
    "    Build and train an LSTM model for load forecasting.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Filter data for the specific state\n",
    "        state_data = data[data['State'] == state_name]['Value'].values\n",
    "        if len(state_data) == 0:\n",
    "            print(f\"No data found for state: {state_name}\")\n",
    "            print(f\"Available states: {data['State'].unique()}\")\n",
    "            return None, None\n",
    "            \n",
    "        state_data = state_data.reshape(-1, 1)\n",
    "        \n",
    "        # Normalize the data\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        state_data = scaler.fit_transform(state_data)\n",
    "        \n",
    "        # Split into train and test sets\n",
    "        train_size = int(len(state_data) * 0.8)\n",
    "        train_data = state_data[0:train_size, :]\n",
    "        test_data = state_data[train_size:len(state_data), :]\n",
    "        \n",
    "        # Reshape into X=t and Y=t+1\n",
    "        X_train, y_train = create_dataset(train_data, time_step)\n",
    "        X_test, y_test = create_dataset(test_data, time_step)\n",
    "        \n",
    "        # Reshape input to be [samples, time steps, features]\n",
    "        X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "        X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "        \n",
    "        # Create the LSTM model\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(50, return_sequences=True, input_shape=(time_step, 1)))\n",
    "        model.add(LSTM(50, return_sequences=False))\n",
    "        model.add(Dense(25))\n",
    "        model.add(Dense(1))\n",
    "        \n",
    "        # Compile the model\n",
    "        model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "        \n",
    "        # Train the model with early stopping\n",
    "        callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            batch_size=32,\n",
    "            epochs=100,\n",
    "            validation_data=(X_test, y_test),\n",
    "            verbose=1,\n",
    "            callbacks=[callback]\n",
    "        )\n",
    "        \n",
    "        # Make predictions\n",
    "        train_predict = model.predict(X_train)\n",
    "        test_predict = model.predict(X_test)\n",
    "        \n",
    "        # Invert predictions to original scale\n",
    "        train_predict = scaler.inverse_transform(train_predict)\n",
    "        test_predict = scaler.inverse_transform(test_predict)\n",
    "        y_train_inv = scaler.inverse_transform([y_train])\n",
    "        y_test_inv = scaler.inverse_transform([y_test])\n",
    "        \n",
    "        # Calculate metrics\n",
    "        train_rmse = np.sqrt(mean_squared_error(y_train_inv[0], train_predict[:,0]))\n",
    "        test_rmse = np.sqrt(mean_squared_error(y_test_inv[0], test_predict[:,0]))\n",
    "        train_r2 = r2_score(y_train_inv[0], train_predict[:,0])\n",
    "        test_r2 = r2_score(y_test_inv[0], test_predict[:,0])\n",
    "        \n",
    "        print(f'State: {state_name}')\n",
    "        print(f'Train RMSE: {train_rmse:.2f}, Test RMSE: {test_rmse:.2f}')\n",
    "        print(f'Train R²: {train_r2:.4f}, Test R²: {test_r2:.4f}')\n",
    "        \n",
    "        return model, scaler\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error building LSTM model: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def predict_next_day_load(model, scaler, recent_data, time_step=24):\n",
    "    \"\"\"\n",
    "    Predict load for the next 24 hours using the LSTM model.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Prepare the input sequence for prediction\n",
    "        recent_data = recent_data.reshape(-1, 1)\n",
    "        recent_data = scaler.transform(recent_data)\n",
    "        \n",
    "        # Reshape for LSTM input\n",
    "        X_input = recent_data.reshape(1, time_step, 1)\n",
    "        \n",
    "        # Get LSTM prediction\n",
    "        prediction = model.predict(X_input)\n",
    "        prediction = scaler.inverse_transform(prediction)[0, 0]\n",
    "        \n",
    "        return prediction\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in prediction: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60519fb5-2049-4f2d-a75d-00639ce281c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import skfuzzy as fuzz\n",
    "from skfuzzy import control as ctrl\n",
    "\n",
    "def create_load_fuzzy_system(min_load, max_load):\n",
    "    \"\"\"\n",
    "    Create a fuzzy inference system for classifying load values.\n",
    "    Returns the fuzzy variable and a function to get the label.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Define input\n",
    "        load = ctrl.Antecedent(np.arange(min_load, max_load + 1, 1), 'load')\n",
    "\n",
    "        # Membership functions\n",
    "        load['very_low'] = fuzz.trimf(load.universe, [min_load, min_load, min_load + (max_load - min_load) * 0.25])\n",
    "        load['low'] = fuzz.trimf(load.universe, [min_load, min_load + (max_load - min_load) * 0.25, min_load + (max_load - min_load) * 0.5])\n",
    "        load['medium'] = fuzz.trimf(load.universe, [min_load + (max_load - min_load) * 0.25, min_load + (max_load - min_load) * 0.5, min_load + (max_load - min_load) * 0.75])\n",
    "        load['high'] = fuzz.trimf(load.universe, [min_load + (max_load - min_load) * 0.5, min_load + (max_load - min_load) * 0.75, max_load])\n",
    "        load['very_high'] = fuzz.trimf(load.universe, [min_load + (max_load - min_load) * 0.75, max_load, max_load])\n",
    "\n",
    "        # Return the Antecedent object and a function to infer label\n",
    "        def infer_load_label(value):\n",
    "            memberships = {label: fuzz.interp_membership(load.universe, load[label].mf, value)\n",
    "                           for label in load.terms}\n",
    "            best_label = max(memberships, key=memberships.get)\n",
    "            return best_label\n",
    "        \n",
    "        return load, infer_load_label\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating fuzzy system: {e}\")\n",
    "        return None, lambda x: \"unknown\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60ce8be8-df3d-4177-b3c5-39d96eea10be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Main Forecasting Function\n",
    "def forecast_load_for_state(data, state_name, time_step=24):\n",
    "    \"\"\"\n",
    "    Forecast load for a specific state using the sequential LSTM + Fuzzy Logic approach.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get state data\n",
    "        state_data = data[data['State'] == state_name]['Value'].values\n",
    "        \n",
    "        # Get min and max load for fuzzy system\n",
    "        min_load = np.min(state_data) * 0.9  # Add some margin\n",
    "        max_load = np.max(state_data) * 1.1\n",
    "        \n",
    "        # Build LSTM model\n",
    "        print(f\"\\nBuilding LSTM model for {state_name}...\")\n",
    "        model, scaler = build_lstm_model(data, state_name, time_step)\n",
    "        \n",
    "        if model is None or scaler is None:\n",
    "            print(f\"Failed to build model for {state_name}. Skipping.\")\n",
    "            return None\n",
    "        \n",
    "        # Create fuzzy system\n",
    "        print(f\"\\nCreating fuzzy logic system for {state_name}...\")\n",
    "        fuzzy_system = create_load_fuzzy_system(min_load, max_load)\n",
    "        \n",
    "        if fuzzy_system is None:\n",
    "            print(f\"Failed to create fuzzy system for {state_name}. Using only LSTM predictions.\")\n",
    "        \n",
    "        # Get recent data for prediction\n",
    "        recent_data = state_data[-time_step:]\n",
    "        \n",
    "        # Forecast for next 24 hours\n",
    "        lstm_predictions = []\n",
    "        fuzzy_predictions = []\n",
    "        \n",
    "        print(f\"\\nForecasting load for next 24 hours for {state_name}...\")\n",
    "        for hour in range(24):\n",
    "            # Get LSTM prediction\n",
    "            lstm_pred = predict_next_day_load(model, scaler, recent_data, time_step)\n",
    "            lstm_predictions.append(lstm_pred)\n",
    "            \n",
    "            # Update recent data for next prediction (rolling forecast)\n",
    "            recent_data = np.append(recent_data[1:], [lstm_pred])\n",
    "\n",
    "        load_system, get_label = create_load_fuzzy_system(min_load, max_load)\n",
    "        \n",
    "        fuzzystrs = [get_label(val) for val in lstm_predictions]\n",
    "        # # Plot results\n",
    "        # plt.figure(figsize=(12, 6))\n",
    "        # plt.plot(range(24), lstm_predictions, 'b-', label='LSTM Predictions')\n",
    "        # plt.plot(range(24), fuzzy_predictions, 'r-', label='Fuzzy Logic Refined')\n",
    "        # plt.title(f'Load Forecast for {state_name} - Next 24 Hours')\n",
    "        # plt.xlabel('Hour')\n",
    "        # plt.ylabel('Load (MW)')\n",
    "        # plt.legend()\n",
    "        # plt.grid(True)\n",
    "        # plt.savefig(f\"{state_name}_forecast.png\")\n",
    "        # plt.close()\n",
    "        \n",
    "        # Return predictions\n",
    "        return {\n",
    "            'state': state_name,\n",
    "            'lstm_predictions': lstm_predictions,\n",
    "            'fuzzy_inference': fuzzystrs\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in forecasting for {state_name}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6abbcd6e-ebb8-4d65-8948-2bbcbb10bbc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Load Forecasting System...\n",
      "Current time: 2025-04-15 17:21:23.777672\n",
      "Data loaded successfully with 29752 rows and 5 columns.\n",
      "\n",
      "Data summary:\n",
      "Time period: 2025-02-11 18:37:29.166139 to 2025-03-26 16:21:12.683044\n",
      "States in the dataset: ['CHANDIGARH' 'HARYANA' 'HIMACHAL' 'J & K' 'PUNJAB' 'RAJASTHAN'\n",
      " 'UTTARAKHAND' 'UTTAR-PRADESH']\n",
      "Load value range: 83 to 21262\n",
      "\n",
      "Building LSTM model for PUNJAB...\n",
      "Epoch 1/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0550 - val_loss: 0.0035\n",
      "Epoch 2/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 3/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0027 - val_loss: 0.0016\n",
      "Epoch 4/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 5/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 6/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - val_loss: 9.2088e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - val_loss: 8.2793e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - val_loss: 7.8318e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - val_loss: 7.8458e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - val_loss: 7.7891e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.8901e-04 - val_loss: 7.4480e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.3439e-04 - val_loss: 7.4501e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.9027e-04 - val_loss: 8.0678e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.5483e-04 - val_loss: 8.7468e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.2081e-04 - val_loss: 9.1764e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 7.8740e-04 - val_loss: 9.3733e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 7.5579e-04 - val_loss: 9.3782e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 7.2656e-04 - val_loss: 9.2204e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6.9984e-04 - val_loss: 8.9242e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6.7555e-04 - val_loss: 8.5153e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6.5354e-04 - val_loss: 8.0265e-04\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "State: PUNJAB\n",
      "Train RMSE: 217.59, Test RMSE: 222.14\n",
      "Train R²: 0.9784, Test R²: 0.9662\n",
      "\n",
      "Creating fuzzy logic system for PUNJAB...\n",
      "\n",
      "Forecasting load for next 24 hours for PUNJAB...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Forecast Results:\n",
      "State: PUNJAB\n",
      "Hour | LSTM Prediction | Fuzzy Logic Refined\n",
      "--------------------------------------------------\n",
      " 0   |        7395.63 | medium\n",
      " 1   |        7208.06 | medium\n",
      " 2   |        7006.54 | medium\n",
      " 3   |        6803.53 | medium\n",
      " 4   |        6600.83 | medium\n",
      " 5   |        6397.57 | medium\n",
      " 6   |        6192.26 | medium\n",
      " 7   |        5983.71 | medium\n",
      " 8   |        5771.38 | medium\n",
      " 9   |        5555.44 | medium\n",
      "10   |        5336.57 | low\n",
      "11   |        5115.84 | low\n",
      "12   |        4894.52 | low\n",
      "13   |        4674.02 | low\n",
      "14   |        4455.76 | low\n",
      "15   |        4241.11 | low\n",
      "16   |        4031.44 | low\n",
      "17   |        3828.10 | low\n",
      "18   |        3632.45 | low\n",
      "19   |        3445.76 | low\n",
      "20   |        3269.28 | low\n",
      "21   |        3104.19 | very_low\n",
      "22   |        2951.58 | very_low\n",
      "23   |        2812.46 | very_low\n",
      "\n",
      "Load Forecasting System completed successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 5. Main Function\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the load forecasting system.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"Starting Load Forecasting System...\")\n",
    "        print(f\"Current time: {datetime.datetime.now()}\")\n",
    "        \n",
    "        # Load the data\n",
    "        file_path = 'export_data.csv.txt' \n",
    "        data = load_data(file_path)\n",
    "        \n",
    "        if data is None:\n",
    "            print(\"Failed to load data. Exiting.\")\n",
    "            return\n",
    "        \n",
    "        # Get list of states\n",
    "        states = data['State'].unique()\n",
    "        \n",
    "        # Select a state for forecasting\n",
    "        state_to_forecast = 'PUNJAB'  # Change this to forecast for a different state\n",
    "        \n",
    "        if state_to_forecast not in states:\n",
    "            print(f\"State {state_to_forecast} not found in data. Available states: {states}\")\n",
    "            state_to_forecast = states[0]\n",
    "            print(f\"Using {state_to_forecast} instead.\")\n",
    "        \n",
    "        # Forecast load for the selected state\n",
    "        forecast_results = forecast_load_for_state(data, state_to_forecast)\n",
    "        \n",
    "        if forecast_results:\n",
    "            print(\"\\nForecast Results:\")\n",
    "            print(f\"State: {forecast_results['state']}\")\n",
    "            print(\"Hour | LSTM Prediction | Fuzzy Logic Refined\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "            for hour, (lstm_pred, fuzzy_pred) in enumerate(zip(\n",
    "                forecast_results['lstm_predictions'], \n",
    "                forecast_results['fuzzy_inference'], \n",
    "            )):\n",
    "                print(f\"{hour:2d}   | {lstm_pred:14.2f} | {fuzzy_pred}\")\n",
    "        \n",
    "        print(\"\\nLoad Forecasting System completed successfully!\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in main function: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f073535-bb1d-4683-a2f9-c96a5be7fe25",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_results = forecast_load_for_state(data, state_to_forecast)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
